# Generated by CodiumAI

import pytest
import torch

from gpt.config import GPTConfig
from gpt.model import GPT


class TestGPT:

    #  GPT model can be instantiated with a valid configuration object
    def test_instantiation_with_valid_config(self):
        config = GPTConfig(vocab_size=100, max_len=512)
        model = GPT(config)
        assert isinstance(model, GPT)
        assert model.config == config

    #  GPT model can be called with a tensor of valid shape
    def test_forward_pass_with_valid_tensor(self):
        config = GPTConfig(vocab_size=100, max_len=128)
        model = GPT(config)
        input_tensor = torch.randint(0, 100, (32, 128))
        output_tensor = model(input_tensor)
        assert output_tensor.shape == (32, 128, 100)
        assert output_tensor.dtype == torch.float32

    #  GPT model raises a ValueError if input sequence length is greater than max_len
    def test_input_sequence_length_greater_than_max_len(self):
        config = GPTConfig(vocab_size=100, max_len=512)
        model = GPT(config)
        input_tensor = torch.randint(0, 100, (32, 513))
        with pytest.raises(ValueError):
            model(input_tensor)

    #  GPT model raises a ValueError if the number of heads is not a divisor of the embedding dimension
    def test_invalid_num_heads(self):
        config = GPTConfig(vocab_size=100, max_len=512, num_heads=10)
        with pytest.raises(ValueError):
            model = GPT(config)

    #  GPT model can be instantiated with a configuration object with default values
    def test_instantiation_with_default_config(self):
        config = GPTConfig(vocab_size=100, max_len=512)
        model = GPT(config)
        assert isinstance(model, GPT)
        assert model.config == config
